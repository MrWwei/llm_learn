#!/usr/bin/env python3
"""
ç»¼åˆæµ‹è¯•è„šæœ¬ - å¯¹æ¯”åŸºç¡€æ¨¡å‹ã€æç¤ºè¯å·¥ç¨‹ã€RAGä¸‰ç§æ¨¡å¼
"""

import os
import json
import torch
import time
from datetime import datetime
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel
from rag_system import RAGSystem
from typing import Dict, List, Any

class ComprehensiveEvaluator:
    """ç»¼åˆè¯„ä¼°å™¨"""
    
    def __init__(self, model_path="./output/final_model", base_model="distilgpt2"):
        self.model_path = model_path
        self.base_model = base_model
        self.model = None
        self.tokenizer = None
        self.rag_system = None
        
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        print("ğŸ“¦ åŠ è½½æ¨¡å‹...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(self.base_model)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        if os.path.exists(self.model_path):
            base_model = AutoModelForCausalLM.from_pretrained(
                self.base_model,
                torch_dtype=torch.float16,
                device_map="auto"
            )
            self.model = PeftModel.from_pretrained(base_model, self.model_path)
        else:
            print("âš ï¸ ä½¿ç”¨åŸºç¡€æ¨¡å‹è¿›è¡Œæµ‹è¯•")
            self.model = AutoModelForCausalLM.from_pretrained(
                self.base_model,
                torch_dtype=torch.float16,
                device_map="auto"
            )
        
        self.model.eval()
        print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_rag_system(self):
        """åŠ è½½RAGç³»ç»Ÿ"""
        print("ğŸ” åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        self.rag_system = RAGSystem(self.model_path, self.base_model)
        self.rag_system.load_model()
        self.rag_system.initialize_knowledge_base()
        print("âœ… RAGç³»ç»Ÿå‡†å¤‡å®Œæˆ")
    
    def generate_basic_response(self, question: str) -> Dict[str, Any]:
        """åŸºç¡€æ¨¡å¼ç”Ÿæˆå›ç­”"""
        start_time = time.time()
        
        prompt = f"Human: {question}\nAssistant:"
        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=200,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        answer = response[len(prompt):].strip()
        
        generation_time = time.time() - start_time
        
        return {
            "mode": "åŸºç¡€æ¨¡å¼",
            "question": question,
            "answer": answer,
            "generation_time": generation_time,
            "prompt_used": prompt
        }
    
    def generate_prompt_engineered_response(self, question: str) -> Dict[str, Any]:
        """æç¤ºè¯å·¥ç¨‹æ¨¡å¼ç”Ÿæˆå›ç­”"""
        start_time = time.time()
        
        # ä½¿ç”¨è§’è‰²æ‰®æ¼” + ç»“æ„åŒ–è¾“å‡ºçš„æç¤ºè¯å·¥ç¨‹
        enhanced_prompt = f"""ä½ æ˜¯ä¸€åèµ„æ·±çš„äººå·¥æ™ºèƒ½ä¸“å®¶ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„ç†è®ºçŸ¥è¯†å’Œå®è·µç»éªŒã€‚è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¯¦ç»†å›ç­”é—®é¢˜ï¼š

ã€æ ¸å¿ƒæ¦‚å¿µã€‘
ã€è¯¦ç»†è§£é‡Šã€‘
ã€å®é™…åº”ç”¨ã€‘
ã€æ€»ç»“ã€‘

é—®é¢˜: {question}

è¯·åŸºäºæ‚¨çš„ä¸“ä¸šçŸ¥è¯†æä¾›å‡†ç¡®ã€å…¨é¢çš„å›ç­”:"""
        
        inputs = self.tokenizer(enhanced_prompt, return_tensors="pt").to(self.model.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=300,
                temperature=0.7,
                top_p=0.9,
                do_sample=True,
                pad_token_id=self.tokenizer.eos_token_id
            )
        
        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        answer = response[len(enhanced_prompt):].strip()
        
        generation_time = time.time() - start_time
        
        return {
            "mode": "æç¤ºè¯å·¥ç¨‹",
            "question": question,
            "answer": answer,
            "generation_time": generation_time,
            "prompt_used": enhanced_prompt
        }
    
    def generate_rag_response(self, question: str) -> Dict[str, Any]:
        """RAGæ¨¡å¼ç”Ÿæˆå›ç­”"""
        start_time = time.time()
        
        result = self.rag_system.generate_rag_response(question, max_new_tokens=300)
        
        generation_time = time.time() - start_time
        result["generation_time"] = generation_time
        result["mode"] = "RAGå¢å¼º"
        
        return result
    
    def evaluate_all_modes(self, test_questions: List[str]) -> Dict[str, Any]:
        """è¯„ä¼°æ‰€æœ‰æ¨¡å¼"""
        results = {
            "basic_mode": [],
            "prompt_engineering": [],
            "rag_mode": [],
            "comparison": []
        }
        
        print("ğŸ§ª å¼€å§‹ç»¼åˆè¯„ä¼°...")
        print("="*80)
        
        for i, question in enumerate(test_questions, 1):
            print(f"\nğŸ“ æµ‹è¯• {i}/{len(test_questions)}: {question}")
            print("-" * 60)
            
            # åŸºç¡€æ¨¡å¼
            print("ğŸ”¸ åŸºç¡€æ¨¡å¼...")
            basic_result = self.generate_basic_response(question)
            results["basic_mode"].append(basic_result)
            print(f"   å›ç­”: {basic_result['answer'][:100]}...")
            
            # æç¤ºè¯å·¥ç¨‹æ¨¡å¼
            print("ğŸ”¸ æç¤ºè¯å·¥ç¨‹æ¨¡å¼...")
            pe_result = self.generate_prompt_engineered_response(question)
            results["prompt_engineering"].append(pe_result)
            print(f"   å›ç­”: {pe_result['answer'][:100]}...")
            
            # RAGæ¨¡å¼
            print("ğŸ”¸ RAGå¢å¼ºæ¨¡å¼...")
            rag_result = self.generate_rag_response(question)
            results["rag_mode"].append(rag_result)
            print(f"   å›ç­”: {rag_result['answer'][:100]}...")
            print(f"   ä½¿ç”¨ä¸Šä¸‹æ–‡: {'æ˜¯' if rag_result.get('context_used', False) else 'å¦'}")
            
            # å¯¹æ¯”åˆ†æ
            comparison = {
                "question": question,
                "basic_length": len(basic_result['answer']),
                "pe_length": len(pe_result['answer']),
                "rag_length": len(rag_result['answer']),
                "basic_time": basic_result['generation_time'],
                "pe_time": pe_result['generation_time'],
                "rag_time": rag_result['generation_time'],
                "rag_used_context": rag_result.get('context_used', False)
            }
            results["comparison"].append(comparison)
            
            print(f"   â±ï¸  ç”Ÿæˆæ—¶é—´ - åŸºç¡€: {basic_result['generation_time']:.2f}s, "
                  f"æç¤ºå·¥ç¨‹: {pe_result['generation_time']:.2f}s, "
                  f"RAG: {rag_result['generation_time']:.2f}s")
        
        return results
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        report = []
        report.append("# å¤§æ¨¡å‹SFT + æç¤ºè¯å·¥ç¨‹ + RAG ç»¼åˆè¯„ä¼°æŠ¥å‘Š")
        report.append(f"\n**è¯„ä¼°æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"**æ¨¡å‹**: {self.base_model}")
        report.append(f"**å¾®è°ƒæ¨¡å‹è·¯å¾„**: {self.model_path}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        comparisons = results["comparison"]
        
        avg_basic_time = sum(c['basic_time'] for c in comparisons) / len(comparisons)
        avg_pe_time = sum(c['pe_time'] for c in comparisons) / len(comparisons)
        avg_rag_time = sum(c['rag_time'] for c in comparisons) / len(comparisons)
        
        avg_basic_length = sum(c['basic_length'] for c in comparisons) / len(comparisons)
        avg_pe_length = sum(c['pe_length'] for c in comparisons) / len(comparisons)
        avg_rag_length = sum(c['rag_length'] for c in comparisons) / len(comparisons)
        
        rag_context_usage = sum(1 for c in comparisons if c['rag_used_context']) / len(comparisons)
        
        report.append("\n## ğŸ“Š æ€§èƒ½ç»Ÿè®¡")
        report.append("\n### ç”Ÿæˆæ—¶é—´å¯¹æ¯”")
        report.append(f"- åŸºç¡€æ¨¡å¼: {avg_basic_time:.2f}s")
        report.append(f"- æç¤ºè¯å·¥ç¨‹: {avg_pe_time:.2f}s")
        report.append(f"- RAGå¢å¼º: {avg_rag_time:.2f}s")
        
        report.append("\n### å›ç­”é•¿åº¦å¯¹æ¯”")
        report.append(f"- åŸºç¡€æ¨¡å¼: {avg_basic_length:.0f} å­—ç¬¦")
        report.append(f"- æç¤ºè¯å·¥ç¨‹: {avg_pe_length:.0f} å­—ç¬¦")
        report.append(f"- RAGå¢å¼º: {avg_rag_length:.0f} å­—ç¬¦")
        
        report.append(f"\n### RAGä¸Šä¸‹æ–‡ä½¿ç”¨ç‡: {rag_context_usage:.1%}")
        
        # è¯¦ç»†ç»“æœ
        report.append("\n## ğŸ“ è¯¦ç»†æµ‹è¯•ç»“æœ")
        
        for i, (basic, pe, rag) in enumerate(zip(results["basic_mode"], 
                                                results["prompt_engineering"], 
                                                results["rag_mode"]), 1):
            report.append(f"\n### æµ‹è¯• {i}: {basic['question']}")
            
            report.append("\n#### åŸºç¡€æ¨¡å¼")
            report.append(f"å›ç­”: {basic['answer']}")
            
            report.append("\n#### æç¤ºè¯å·¥ç¨‹æ¨¡å¼")
            report.append(f"å›ç­”: {pe['answer']}")
            
            report.append("\n#### RAGå¢å¼ºæ¨¡å¼")
            report.append(f"å›ç­”: {rag['answer']}")
            if rag.get('context_used'):
                report.append("âœ… ä½¿ç”¨äº†çŸ¥è¯†åº“ä¸Šä¸‹æ–‡")
            else:
                report.append("âŒ æœªä½¿ç”¨çŸ¥è¯†åº“ä¸Šä¸‹æ–‡")
        
        report.append("\n## ğŸ¯ è¯„ä¼°ç»“è®º")
        report.append("\n### ä¼˜åŠ¿å¯¹æ¯”")
        report.append("- **åŸºç¡€æ¨¡å¼**: é€Ÿåº¦æœ€å¿«ï¼Œä½†å›ç­”å¯èƒ½ä¸å¤Ÿå‡†ç¡®")
        report.append("- **æç¤ºè¯å·¥ç¨‹**: å›ç­”æ›´ç»“æ„åŒ–ï¼Œè´¨é‡æœ‰æ‰€æå‡")
        report.append("- **RAGå¢å¼º**: åŸºäºçŸ¥è¯†åº“ï¼Œå›ç­”æœ€å‡†ç¡®å¯é ")
        
        report.append("\n### æ¨èä½¿ç”¨åœºæ™¯")
        report.append("- **å¿«é€Ÿé—®ç­”**: åŸºç¡€æ¨¡å¼")
        report.append("- **ç»“æ„åŒ–å›ç­”**: æç¤ºè¯å·¥ç¨‹æ¨¡å¼")
        report.append("- **å‡†ç¡®æ€§è¦æ±‚é«˜**: RAGå¢å¼ºæ¨¡å¼")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¤§æ¨¡å‹SFT + æç¤ºè¯å·¥ç¨‹ + RAG ç»¼åˆè¯„ä¼°")
    print("="*80)
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = ComprehensiveEvaluator()
    
    try:
        # åŠ è½½ç»„ä»¶
        evaluator.load_model()
        evaluator.load_rag_system()
        
        # æµ‹è¯•é—®é¢˜
        test_questions = [
            "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "Pythonä¸ºä»€ä¹ˆé€‚åˆåšæ•°æ®ç§‘å­¦ï¼Ÿ",
            "ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
            "è‡ªç„¶è¯­è¨€å¤„ç†æœ‰å“ªäº›åº”ç”¨ï¼Ÿ"
        ]
        
        # æ‰§è¡Œè¯„ä¼°
        results = evaluator.evaluate_all_modes(test_questions)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = evaluator.generate_report(results)
        
        # ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ä¿å­˜JSONç»“æœ
        json_file = f"comprehensive_evaluation_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜MarkdownæŠ¥å‘Š
        report_file = f"evaluation_report_{timestamp}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("\n" + "="*80)
        print("âœ… ç»¼åˆè¯„ä¼°å®Œæˆï¼")
        print(f"ğŸ“Š JSONç»“æœ: {json_file}")
        print(f"ğŸ“„ è¯„ä¼°æŠ¥å‘Š: {report_file}")
        print("="*80)
        
        # æ˜¾ç¤ºç®€è¦ç»“æœ
        print("\nğŸ“‹ è¯„ä¼°æ‘˜è¦:")
        comparisons = results["comparison"]
        avg_times = {
            "åŸºç¡€æ¨¡å¼": sum(c['basic_time'] for c in comparisons) / len(comparisons),
            "æç¤ºè¯å·¥ç¨‹": sum(c['pe_time'] for c in comparisons) / len(comparisons),
            "RAGå¢å¼º": sum(c['rag_time'] for c in comparisons) / len(comparisons)
        }
        
        for mode, time_val in avg_times.items():
            print(f"  {mode}: å¹³å‡ {time_val:.2f}s/é—®é¢˜")
        
        rag_usage = sum(1 for c in comparisons if c['rag_used_context'])
        print(f"  RAGä¸Šä¸‹æ–‡ä½¿ç”¨: {rag_usage}/{len(comparisons)} æ¬¡")
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
